# ğŸ›°ï¸ DA5401 â€“ Assignment 7  
## Multi-Class Model Selection using ROC & Precisionâ€“Recall Curves

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)
![Status](https://img.shields.io/badge/Status-Complete-green.svg)
![Grade](https://img.shields.io/badge/Grade-100%25-brightgreen.svg)

</div>

---

### ğŸ“Œ Course: *Advanced Data Analytics (DA5401)*  
### ğŸ‘¤ Student: **Shivam Tiwari (DA25C019), IIT Madras**

---

## ğŸ“Œ Project Overview

This assignment focuses on **multi-class model evaluation and selection** using advanced performance metrics beyond accuracy.  
Nine machine learning models (6 required + 3 bonus) are evaluated using:

- âœ… **ROC-AUC (One-vs-Rest)**
- âœ… **Precisionâ€“Recall Curve (PRC) and Average Precision**
- âœ… **Macro F1-Score**

Dataset used: **UCI Landsat Satellite (6 land cover classes, 36 spectral band features).**

> ğŸ¯ Goal: Identify the **best** model for multi-class land cover classification.

---

## ğŸ—‚ Project Structure
â”œâ”€â”€ DA5401_Assignment_7_Multi_Class_Model_Selection.ipynb   # Main notebook
â”œâ”€â”€ sat.trn                                                 # Training dataset
â”œâ”€â”€ sat.tst                                                 # Testing dataset
â”œâ”€â”€ DA5401_A7_Assignment.pdf                                # Problem statement
â””â”€â”€ README.md                                               # Documentation


---

## ğŸ“Š Models Compared

| Category | Models |
|----------|--------|
| **Required Models (6)** | KNN, Decision Tree, Dummy (Prior), Logistic Regression, Gaussian NB, SVC (probability=True) |
| **Bonus Models (3)** | Random Forest, XGBoost, Custom *BadClassifier* (inverted probabilities, AUC < 0.5) |

---

## âœ… Key Implementation Steps

### 1. Data Preparation
- Combined `sat.trn` + `sat.tst` â†’ **6,435 samples**
- Applied **StandardScaler**
- Stratified **80/20** train-test split
- Encoded labels into `[0,1,2,3,4,5]` for XGBoost compatibility

### 2. Model Training
- Every model wrapped in **One-vs-Rest (OvR)** for multi-class ROC/PRC

### 3. Evaluation Metrics
- **ROC-AUC (Macro-Average)**
- **Average Precision (Macro-PRC-AP)**
- **Weighted Macro F1-Score**

---

## ğŸ† Results

### âœ… Overall Performance

| Model | Macro F1 | ROC-AUC (Macro) | PRC-AP (Macro) |
|--------|---------|----------------|----------------|
| **XGBoost** | **0.9158** | **0.9926** | **0.9416** |
| **Random Forest** | 0.9079 | 0.9908 | 0.9388 |
| **SVC (linear)** | 0.8521 | 0.9634 | 0.8804 |
| Dummy (Prior) | 0.0543 | 0.5000 | 0.1670 |
| **BadClassifier (custom)** | 0.1002 | **0.0381** | 0.1343 |

### ğŸ¥‡ Final Recommendation

> **XGBoost** is the best performing model â€” highest ROC-AUC, PRC-AP, and F1-Score.

---

## ğŸš€ How to Run

### Install dependencies
pip install pandas numpy matplotlib seaborn scikit-learn xgboost jupyter

Launch notebook
jupyter notebook DA5401_Assignment_7_Multi_Class_Model_Selection.ipynb

Ensure sat.trn and sat.tst are in the same folder as the .ipynb.

Concepts Used
	â€¢	One-vs-Rest (OvR): Convert multi-class problem into binary comparisons
	â€¢	Macro-Averaging: Gives equal weight to each class
	â€¢	Precisionâ€“Recall Curves: More useful than ROC when classes are imbalanced
	â€¢	BadClassifier: Custom probability inversion to demonstrate AUC < 0.5 model

 
 Author

Shivam Tiwari
DA25C019 â€” IIT Madras


